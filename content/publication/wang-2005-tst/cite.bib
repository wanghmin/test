@inproceedings{Wang:2005:TST,
 abstract = {So far extending light field rendering to dynamic scenes has been trivially treated as the rendering of static light fields stacked in time. This type of approaches requires input video sequences in strict synchronization and allows only discrete exploration in the temporal domain determined by the capture rate. In this paper we propose a novel framework, space-time light field rendering, which allows continuous exploration of a dynamic scene in both spatial and temporal domain with unsynchronized input video sequences. In order to synthesize novel views from any viewpoint at any time instant, we develop a two-stage rendering algorithm. We first interpolate in the temporal domain to generate globally synchronized images using a robust spatial-temporal image registration algorithm followed by edge-preserving image morphing. We then interpolate those software-synchronized images in the spatial domain to synthesize the final view. Our experimental results show that our approach is robust and capable of maintaining photo-realistic results.},
 address = {New York, NY, USA},
 author = {Wang, Huamin and Yang, Ruigang},
 booktitle = {Proceedings of the 2005 Symposium on Interactive 3D Graphics and Games},
 doi = {10.1145/1053427.1053448},
 isbn = {1595930132},
 keywords = {space-time light field, image-based rendering, epipolar constraints},
 location = {Washington, District of Columbia},
 month = {apr},
 numpages = {8},
 pages = {125-132},
 publisher = {Association for Computing Machinery},
 series = {I3D '05},
 title = {Towards Space-Time Light Field Rendering},
 url = {https://doi.org/10.1145/1053427.1053448},
 year = {2005}
}
