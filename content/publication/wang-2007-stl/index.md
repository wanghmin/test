---
title: Space-Time Light Field Rendering
authors:
- admin
- Mingxuan Sun
- Ruigang Yang
date: '2007-07-01'
publishDate: '2024-02-29T05:26:53.841281Z'
publication_types:
- article-journal
publication: '*IEEE Transactions on Visualization and Computer Graphics, 13*(4)'

abstract: In this paper, we propose a novel framework called space-time light field
  rendering, which allows continuous exploration of a dynamic scene in both space
  and time. Compared to existing light field capture/rendering systems, it offers
  the capability of using unsynchronized video inputs and the added freedom of controlling
  the visualization in the temporal domain, such as smooth slow motion and temporal
  integration. In order to synthesize novel views from any viewpoint at any time instant,
  we develop a two-stage rendering algorithm. We first interpolate in the temporal
  domain to generate globally synchronized images using a robust spatial-temporal
  image registration algorithm followed by edge-preserving image morphing. We then
  interpolate these software-synchronized images in the spatial domain to synthesize
  the final view. In addition, we introduce a very accurate and robust algorithm to
  estimate subframe temporal offsets among input video sequences. Experimental results
  from unsynchronized videos with or without time stamps show that our approach is
  capable of maintaining photorealistic quality from a variety of real scenes.
summary: In this paper, we propose a novel framework called space-time light field
  rendering, which allows continuous exploration of a dynamic scene in both space
  and time.
tags:
- layout
- robustness
- motion control
- lighting control
- control systems
- visualization
- control system synthesis
- rendering (computer graphics)
- image generation
- image registration
- image-based rendering
- space-time light field
- epipolar constraint
- image morphing
featured: false
---
